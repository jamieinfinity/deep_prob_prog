{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## PyTorch quick overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Following along with: https://github.com/vahidk/EffectivePyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = torch.randn([3, 5])\n",
    "y = torch.randn([3, 5])\n",
    "z = x +y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = torch.randn([3, 5])\n",
    "y = torch.randn([5, 4])\n",
    "z = x @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6630, -1.5812,  0.6480, -0.3322, -2.1186],\n",
       "        [-1.7094, -0.6856,  0.2842, -0.0681, -0.5432],\n",
       "        [ 1.7740,  3.2653, -0.6112, -0.1560, -1.7339]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.6630206  -1.5812199   0.6480304  -0.33221006 -2.1185994 ]\n",
      " [-1.7094072  -0.68564904  0.28417927 -0.0680545  -0.5431815 ]\n",
      " [ 1.7739999   3.265318   -0.61121875 -0.15603794 -1.7338973 ]]\n"
     ]
    }
   ],
   "source": [
    "print(z.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(np.random.normal(0, 1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 9],\n",
       "        [1, 2, 3],\n",
       "        [1, 1, 1]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = torch.stack([x*x, x, torch.ones_like(x)])\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Auto differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def u(x):\n",
    "    return x * x\n",
    "\n",
    "def g(u):\n",
    "    return -u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "dgdx = torch.autograd.grad(g(u(x)), x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgdx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Curve fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Assuming we know that the desired function is a polynomial of 2nd degree, we\n",
    "# allocate a vector of size 3 to hold the coefficients and initialize it with\n",
    "# random noise.\n",
    "w = torch.tensor(torch.randn([3, 1]).numpy(), requires_grad=True)\n",
    "\n",
    "# We use the Adam optimizer with learning rate set to 0.1 to minimize the loss.\n",
    "opt = torch.optim.Adam([w], lr=0.1)\n",
    "\n",
    "def generate_data(sample_size=100):\n",
    "    # Generate some training data based on the true function\n",
    "    x = torch.rand(sample_size) * 20 - 10\n",
    "    y = 5 * x * x + 3\n",
    "    return x, y\n",
    "\n",
    "def model(x):\n",
    "    # stack: if x=1d tensor, default dim=0 stacks tensors row-wise\n",
    "    # if dim=1, it stacks tensors column wise\n",
    "    f = torch.stack([x * x, x, torch.ones_like(x)], dim=1)\n",
    "    # the matrix mult. @ does a column by column multiplication and sum\n",
    "    # resulting in a tensor of shape [sample_size, 1]\n",
    "    # the squeeze operation flattens out along dim=1, resulting in a shape of [sample_size]\n",
    "    yhat = torch.squeeze(f @ w, 1)\n",
    "    return yhat\n",
    "\n",
    "def compute_loss(y, yhat):\n",
    "    # The loss is defined to be the mean squared error distance between our\n",
    "    # estimate of y and its true value. \n",
    "    loss = torch.nn.functional.mse_loss(yhat, y)\n",
    "    return loss\n",
    "\n",
    "def train_step():\n",
    "    # this is an unorthodox procedure, in that it's generating new training data with each \n",
    "    # iteration of the optimization (but that's ok, it's just a simple example for illustration)\n",
    "    x, y = generate_data()\n",
    "\n",
    "    yhat = model(x)\n",
    "    loss = compute_loss(y, yhat)\n",
    "\n",
    "    # zero_grad clears old gradients from the last step (otherwise youâ€™d just accumulate the gradients from all loss.backward() calls).\n",
    "    opt.zero_grad()\n",
    "    # loss.backward() computes the derivative of the loss w.r.t. the parameters (or anything requiring gradients) using backpropagation.\n",
    "    loss.backward()\n",
    "    # opt.step() causes the optimizer to take a step based on the gradients of the parameters.\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.0000000e+00]\n",
      " [5.6027898e-06]\n",
      " [3.0000026e+00]]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10000):\n",
    "    train_step()\n",
    "    \n",
    "print(w.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Encapsulate your model with Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.rand(1))\n",
    "        self.b = torch.nn.Parameter(torch.rand(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        yhat = self.a * x + self.b\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = torch.arange(100, dtype=torch.float32)\n",
    "\n",
    "net = Net()\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3782,  1.1874,  1.9966,  2.8058,  3.6150,  4.4242,  5.2334,  6.0426,\n",
       "         6.8518,  7.6610,  8.4702,  9.2794, 10.0886, 10.8978, 11.7070, 12.5163,\n",
       "        13.3255, 14.1347, 14.9439, 15.7531, 16.5623, 17.3715, 18.1807, 18.9899,\n",
       "        19.7991, 20.6083, 21.4175, 22.2267, 23.0359, 23.8451, 24.6543, 25.4635,\n",
       "        26.2727, 27.0819, 27.8911, 28.7004, 29.5096, 30.3188, 31.1280, 31.9372,\n",
       "        32.7464, 33.5556, 34.3648, 35.1740, 35.9832, 36.7924, 37.6016, 38.4108,\n",
       "        39.2200, 40.0292, 40.8384, 41.6476, 42.4568, 43.2660, 44.0752, 44.8845,\n",
       "        45.6937, 46.5029, 47.3121, 48.1213, 48.9305, 49.7397, 50.5489, 51.3581,\n",
       "        52.1673, 52.9765, 53.7857, 54.5949, 55.4041, 56.2133, 57.0225, 57.8317,\n",
       "        58.6409, 59.4501, 60.2593, 61.0686, 61.8778, 62.6870, 63.4962, 64.3054,\n",
       "        65.1146, 65.9238, 66.7330, 67.5422, 68.3514, 69.1606, 69.9698, 70.7790,\n",
       "        71.5882, 72.3974, 73.2066, 74.0158, 74.8250, 75.6342, 76.4435, 77.2527,\n",
       "        78.0619, 78.8711, 79.6803, 80.4895], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.8092], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3782], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = torch.arange(100, dtype=torch.float32) / 100\n",
    "y = 5 * x + 3 + torch.rand(100) * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([5.0229], requires_grad=True) Parameter containing:\n",
      "tensor([3.0903], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
    "\n",
    "for i in range(10000):\n",
    "    net.zero_grad()\n",
    "    yhat = net(x)\n",
    "    loss = criterion(yhat, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(net.a, net.b) # Should be close to 5 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x.unsqueeze(1)).squeeze(1)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.7793]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9291], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "for p in net.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## MNIST example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# download MNIST data if it doesn't already exist\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)\n",
    "\n",
    "# load data into memory\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
    "        \n",
    "# x_train, y_train, x_valid, y_valid = map(\n",
    "#     torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64  # batch size\n",
    "IMAGE_SIZE = 28\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.1\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, IMAGE_SIZE, IMAGE_SIZE).to(dev), y.to(dev)\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "    \n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "    \n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    # loop through epochs\n",
    "    for epoch in range(epochs):\n",
    "        # loop through all batches, adjusts weights via opt and loss_func\n",
    "        model.train() # put model in training mode (for things like dropout)\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        # calculate validation loss\n",
    "        model.eval() # put model in evaluation mode (for things like dropout)\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, BATCH_SIZE)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class Model_Mnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "#         xb = xb.view(-1, 1, 28, 28) # taken care of elsewhere\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        xb = F.adaptive_avg_pool2d(xb, 1)\n",
    "        return xb.view(xb.size(0), -1)\n",
    "\n",
    "# this is an alternvative approach:\n",
    "# model = nn.Sequential(\n",
    "#     nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.AdaptiveAvgPool2d(1),\n",
    "#     Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "# )\n",
    "# model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.40164050693511966\n",
      "1 0.2609086702346802\n",
      "2 0.21069078912734984\n",
      "3 0.18539587030410767\n",
      "4 0.15602415542602538\n",
      "5 0.14978277006149293\n",
      "6 0.17158050298690797\n",
      "7 0.17087437171936035\n",
      "8 0.1390433889389038\n",
      "9 0.13101934118270875\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# CPU times: user 2min 54s, sys: 1min 17s, total: 4min 11s\n",
    "# Wall time: 1min 24s\n",
    "\n",
    "model = Model_Mnist()\n",
    "model.to(dev)\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "opt = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "fit(EPOCHS, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9630, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def count_correct(y_pred, y_truth):\n",
    "    preds = torch.argmax(y_pred, dim=1)\n",
    "    return (preds == y_truth).float().sum()\n",
    "\n",
    "model.eval()\n",
    "cc = 0\n",
    "tot = 0\n",
    "with torch.no_grad():\n",
    "    for xb, yb in valid_dl:\n",
    "        y_pred = model(xb)\n",
    "        tot += len(y_pred)\n",
    "        cc += count_correct(y_pred, yb)\n",
    "accuracy = cc/tot\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "preds = model(x_valid.view(-1,1,28,28).to(dev))\n",
    "preds = torch.argmax(preds, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = np.random.choice(range(len(preds)))\n",
    "print(preds[ind].item())\n",
    "plt.imshow(x_valid[ind].reshape((28, 28)), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Save / load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"models\")\n",
    "MNIST_MODEL_PATH = MODEL_PATH / \"mnist\"\n",
    "\n",
    "MNIST_MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "FILENAME = (MNIST_MODEL_PATH / \"mnist_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# save model state\n",
    "torch.save(model.state_dict(), FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_saved = nn.Sequential(\n",
    "#     nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.AdaptiveAvgPool2d(1),\n",
    "#     Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "# )\n",
    "# model_saved.to(dev)\n",
    "\n",
    "model_saved = Model_Mnist()\n",
    "model_saved.to(dev)\n",
    "\n",
    "model_saved.load_state_dict(torch.load(FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9630, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def count_correct(y_pred, y_truth):\n",
    "    preds = torch.argmax(y_pred, dim=1)\n",
    "    return (preds == y_truth).float().sum()\n",
    "\n",
    "model_saved.eval()\n",
    "cc = 0\n",
    "tot = 0\n",
    "with torch.no_grad():\n",
    "    for xb, yb in valid_dl:\n",
    "        y_pred = model_saved(xb)\n",
    "        tot += len(y_pred)\n",
    "        cc += count_correct(y_pred, yb)\n",
    "accuracy = cc/tot\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
